import psycopg2
import requests
import xml.etree.ElementTree as ET
from requests.adapters import HTTPAdapter
import ssl
from datetime import datetime, timedelta

# ì„œìš¸ ì¬ê°œë°œ ì§€ì—­ API í‚¤
API_KEY = "794b46457766676836364c49634b54"
REAL_TRANSACTION_KEY = "c9SfMeQ61ARlLbsN9lIWjaUmHDXw4UN0Xu2BjXhyqN0xHJM/oNEQBh5zXiEZwmPrQ8GXCdy9xI2shXZxRljO/A=="

# PostgreSQL ì—°ê²° ì •ë³´
conn = psycopg2.connect(
    dbname="housing",
    user="postgres",
    password="1234",
    host="localhost",  # ë˜ëŠ” "127.0.0.1"
    port="5432"
)
cursor = conn.cursor()

# ì‹¤í–‰ ì „ ê¸°ì¡´ ë°ì´í„° ëª¨ë‘ ì‚­ì œ
cursor.execute("DELETE FROM real_estate_deals")
conn.commit()
print("ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ âœ…")

# ë‚ ì§œ ê³„ì‚° ë¡œì§ - ìµœê·¼ 3ê°œì›” êµ¬í•˜ê¸°
today = datetime.now()
recent_3_months = []

for i in range(1, 4):  # 1, 2, 3ê°œì›” ì „
    month = today.month - i
    year = today.year
    if month <= 0:
        month += 12
        year -= 1
    deal_day = f"{year}{month:02d}"
    recent_3_months.append(deal_day)

# ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ë™ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
unique_neighborhoods = []
unique_law_dong_codes = []

count = 0

class TLSAdapter(HTTPAdapter):
    def init_poolmanager(self, *args, **kwargs):
        context = ssl.create_default_context()
        # OpenSSLì˜ ë³´ì•ˆ ìˆ˜ì¤€ì„ ë‚®ì¶¤ (SECLEVEL=1)
        context.set_ciphers('DEFAULT@SECLEVEL=1')
        kwargs['ssl_context'] = context
        return super().init_poolmanager(*args, **kwargs)

# ì¬ê°œë°œ ì§€ì—­ api
def get_redevelopment_info(district, neighborhood=None):
    """ì£¼ì–´ì§„ êµ¬(district)ì™€ ë™(neighborhood)ì— ëŒ€í•œ ì¬ê°œë°œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""

    # í•œ ë²ˆì— ê°€ì ¸ì˜¬ ë°ì´í„° ìˆ˜ (ìµœëŒ€ 100ê°œ)
    page_start = 1
    page_end = 100

    all_business_info = []  # ëª¨ë“  ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

    # neighborhood ê°’ì´ ì—†ìœ¼ë©´ í•´ë‹¹ êµ¬ì˜ ëª¨ë“  ì¬ê°œë°œ ì •ë³´ë¥¼ ê°€ì ¸ì˜´
    if neighborhood:
        url = f"http://openapi.seoul.go.kr:8088/{API_KEY}/xml/CleanupBussinessInfo/{page_start}/{page_end}/{district}/{neighborhood}"
    else:
        url = f"http://openapi.seoul.go.kr:8088/{API_KEY}/xml/CleanupBussinessInfo/{page_start}/{page_end}/{district}"

    response = requests.get(url)

    if response.status_code == 200:
        # XML íŒŒì‹±
        root = ET.fromstring(response.text)
        business_info = []

        # XMLì—ì„œ row íƒœê·¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬
        for row in root.iter('row'):
            business_data = {}

            # ê¸°ë³¸ì ì¸ ì •ë³´ ì¶”ì¶œ
            business_data['district'] = district
            business_data['neighborhood'] = neighborhood if neighborhood else row.find('STDG_NM').text or "ì •ë³´ ì—†ìŒ"
            business_data['law_dong_code'] = row.find('BIZ_NO').text if row.find('BIZ_NO') is not None else None
            business_data['business_name'] = row.find('ASCT_NM').text if row.find('ASCT_NM') is not None else None

            # ì¶”ê°€ëœ í•­ëª©ë“¤
            business_data['business_type'] = row.find('BIZ_SE').text if row.find('BIZ_SE') is not None else None
            business_data['approval_status'] = row.find('PRGRS_SEQ').text if row.find('PRGRS_SEQ') is not None else None
            business_data['construction_name'] = row.find('OPER_SE').text if row.find('OPER_SE') is not None else None

            if business_data['business_type'] == "ì¬ê°œë°œ(ì£¼íƒì •ë¹„í˜•)":
                business_info.append(business_data)

        all_business_info.extend(business_info)

    else:
        print("API ìš”ì²­ ì‹¤íŒ¨:", response.status_code)

    return all_business_info

# ë‹¨ë… ë‹¤ê°€êµ¬ ë§¤ë§¤ ì‹¤ê±°ë˜ê°€ api
def get_real_single_family_home_deals(law_code, deal_ymd, api_key):
    """ì‹¤ê±°ë˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    url = "http://apis.data.go.kr/1613000/RTMSDataSvcSHTrade/getRTMSDataSvcSHTrade"

    page_size = 100
    page_start = 1
    all_deals = []
    seen_deals = set()  # ì¤‘ë³µ ê±°ë˜ë¥¼ ì¶”ì í•  set

    while True:
        params = {
            "LAWD_CD": law_code,
            "DEAL_YMD": deal_ymd,
            "serviceKey": api_key,
            "pageNo": page_start,
            "numOfRows": page_size,
            "type": "xml"
        }

        response = requests.get(url, params=params)

        if response.status_code == 200:
            try:
                root = ET.fromstring(response.text)
                items = root.findall('.//item')

                if not items:  # ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
                    break

                for item in items:
                    # ê±°ë˜ ë°ì´í„°ë¥¼ ì¶”ì¶œ
                    deal_data = {
                        'deal_year': item.findtext('dealYear'),
                        'deal_month': item.findtext('dealMonth'),
                        'umdNm': item.findtext('umdNm'),
                        'deal_day': item.findtext('dealDay'),
                        'deal_amount': item.findtext('dealAmount'),
                        'house_type': item.findtext('houseType'),
                        'jibun': item.findtext('jibun'),
                        'plottage_area': item.findtext('plottageAr')
                    }

                    # ê±°ë˜ì˜ ê³ ìœ ì„±ì„ ê²°ì •í•  ì‹ë³„ì (ì¤‘ë³µ íŒë‹¨ ê¸°ì¤€)
                    deal_identifier = (deal_data['deal_year'], deal_data['deal_month'], deal_data['deal_day'], deal_data['umdNm'], deal_data['jibun'])

                    # ì¤‘ë³µëœ ê±°ë˜ì¸ì§€ í™•ì¸
                    if deal_identifier not in seen_deals:
                        all_deals.append(deal_data)  # ì¤‘ë³µì´ ì•„ë‹ˆë©´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                        seen_deals.add(deal_identifier)  # ì¤‘ë³µ ì²˜ë¦¬ëœ ê±°ë˜ë¡œ ë“±ë¡

                print(f"ë‹¨ë… ë‹¤ê°€êµ¬ í˜ì´ì§€ {page_start} ì²˜ë¦¬ ì™„ë£Œ, í˜„ì¬ê¹Œì§€ {len(all_deals)}ê°œ ë°ì´í„° ìˆ˜ì§‘ë¨")
                page_start += 1  # ë‹¤ìŒ í˜ì´ì§€ ìš”ì²­

            except ET.ParseError:
                print("XML íŒŒì‹± ì—ëŸ¬ ë°œìƒ")
                print(response.text)  # ì‘ë‹µ ë‚´ìš© ì¶œë ¥
                return []
        else:
            print(f"API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
            print(response.text)  # ì‘ë‹µ ë‚´ìš© ì¶œë ¥
            break

    return all_deals

# ì—°ë¦½ ë‹¤ì„¸ëŒ€ ë§¤ë§¤ ì‹¤ê±°ë˜ api
def get_villa_deals(law_code, deal_ymd, api_key):
    """ì—°ë¦½ ë‹¤ì„¸ëŒ€ ì‹¤ê±°ë˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ (XML ì‘ë‹µ)"""
    url = "https://apis.data.go.kr/1613000/RTMSDataSvcRHTrade/getRTMSDataSvcRHTrade"

    page_size = 100
    page_start = 1
    all_deals = []
    seen_deals = set()  # ì¤‘ë³µ ê±°ë˜ë¥¼ ì¶”ì í•  set

    session = requests.Session()
    session.mount("https://", TLSAdapter())

    while True:
        params = {
            "LAWD_CD": law_code,  # ì˜ˆ: 11680
            "DEAL_YMD": deal_ymd,  # ì˜ˆ: 202503
            "serviceKey": api_key,
            "pageNo": page_start,
            "numOfRows": page_size,
            "type": "xml"  # XML í˜•ì‹ìœ¼ë¡œ ìš”ì²­
        }

        try:
            response = session.get(url, params=params, timeout=30)
        except requests.exceptions.RequestException as e:
            print(f"ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            break

        if response.status_code == 200:
            try:
                root = ET.fromstring(response.text)
                items = root.findall('.//item')

                if not items:  # ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
                    break

                for item in items:
                    # ê±°ë˜ ë°ì´í„°ë¥¼ ì¶”ì¶œ
                    deal_data = {
                        'deal_year': item.findtext('dealYear'),
                        'deal_month': item.findtext('dealMonth'),
                        'deal_day': item.findtext('dealDay'),
                        'umdNm': item.findtext('umdNm'),
                        'house_type': item.findtext('houseType'),
                        'deal_amount': item.findtext('dealAmount'),
                        'jibun': item.findtext('jibun'),
                        'floor': item.findtext('floor'),
                        'exclu_use_ar': item.findtext('excluUseAr')
                    }

                    # ê±°ë˜ì˜ ê³ ìœ ì„±ì„ ê²°ì •í•  ì‹ë³„ì (ì¤‘ë³µ íŒë‹¨ ê¸°ì¤€)
                    deal_identifier = (deal_data['deal_year'], deal_data['deal_month'], deal_data['deal_day'], deal_data['umdNm'], deal_data['jibun'])

                    # ì¤‘ë³µëœ ê±°ë˜ì¸ì§€ í™•ì¸
                    if deal_identifier not in seen_deals:
                        all_deals.append(deal_data)  # ì¤‘ë³µì´ ì•„ë‹ˆë©´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                        seen_deals.add(deal_identifier)  # ì¤‘ë³µ ì²˜ë¦¬ëœ ê±°ë˜ë¡œ ë“±ë¡

                print(f"ì—°ë¦½ ë‹¤ì„¸ëŒ€ í˜ì´ì§€ {page_start} ì²˜ë¦¬ ì™„ë£Œ, í˜„ì¬ê¹Œì§€ {len(all_deals)}ê°œ ë°ì´í„° ìˆ˜ì§‘ë¨")
                page_start += 1  # ë‹¤ìŒ í˜ì´ì§€ ìš”ì²­

            except ET.ParseError as e:
                print(f"XML íŒŒì‹± ì˜¤ë¥˜: {e}")
                print(response.text)
                break
        else:
            print(f"API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
            print(response.text)
            break

    return all_deals

# í† ì§€ ë§¤ë§¤ ì‹¤ê±°ë˜ api
def get_land_sale_deals(law_code, deal_ymd, api_key):

    url = "https://apis.data.go.kr/1613000/RTMSDataSvcLandTrade/getRTMSDataSvcLandTrade"

    page_size = 100
    page_start = 1
    all_deals = []

    session = requests.Session()
    session.mount("https://", TLSAdapter())

    while True:
        params = {
            "LAWD_CD": law_code,
            "DEAL_YMD": deal_ymd,
            "serviceKey": api_key,
            "pageNo": page_start,
            "numOfRows": page_size,
            "type": "xml"  # XML í˜•ì‹ìœ¼ë¡œ ìš”ì²­
        }

        try:
            response = session.get(url, params=params, timeout=30)
        except requests.exceptions.RequestException as e:
            print(f"ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            break

        if response.status_code == 200:
            try:
                root = ET.fromstring(response.text)
                items = root.findall('.//item')

                if not items:  # ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
                    break

                for item in items:
                    deal_data = {
                        'deal_year': item.findtext('dealYear'),
                        'deal_month': item.findtext('dealMonth'),
                        'deal_day': item.findtext('dealDay'),
                        'umdNm': item.findtext('umdNm'),
                        'jibun': item.findtext('jibun'),
                        'deal_amount': item.findtext('dealAmount'),
                        'deal_area': item.findtext('dealArea'),
                        'jimok': item.findtext('jimok'),
                        'land_use': item.findtext('landUse'),
                        'share_dealing_type': item.findtext('shareDealingType'),
                        'dealing_gbn': item.findtext('dealingGbn'),
                    }
                    all_deals.append(deal_data)

                print(f"í† ì§€ ë§¤ë§¤ í˜ì´ì§€ {page_start} ì²˜ë¦¬ ì™„ë£Œ, í˜„ì¬ê¹Œì§€ {len(all_deals)}ê°œ ë°ì´í„° ìˆ˜ì§‘ë¨")
                page_start += 1
            except ValueError as e:
                print(f"XML íŒŒì‹± ì˜¤ë¥˜: {e}")
                print(response.text)
                break
        else:
            print(f"API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
            print(response.text)
            break

    return all_deals

# ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ë™ ë¦¬ìŠ¤íŠ¸ì™€ ë§¤ë§¤ ì‹¤ê±°ë˜ê°€ í•„í„°
def filter_real_deals(real_estate_deals, unique_neighborhoods):
    """umdNm ê°’ì´ unique_neighborhoodsì— í¬í•¨ëœ ë°ì´í„°ë§Œ í•„í„°ë§"""
    return [deal for deal in real_estate_deals if deal.get('umdNm') in unique_neighborhoods]

# ê³µí†µ INSERT í•¨ìˆ˜
def insert_real_estate_data(cursor, conn, deal_list, data_type):
    for item in deal_list:
        # ê±°ë˜ê¸ˆì•¡ì—ì„œ ì½¤ë§ˆ ì œê±° í›„ long íƒ€ì…ìœ¼ë¡œ ë³€í™˜
        deal_amount = item.get('deal_amount').replace(',', '')  # ì½¤ë§ˆ ì œê±°
        deal_amount = int(deal_amount)  # ìˆ«ìë¡œ ë³€í™˜

        cursor.execute("""
            INSERT INTO real_estate_deals (
                deal_year, deal_month, deal_day, district, neighborhood,
                deal_amount, house_type, apt_name, jibun, floor,
                exclu_use_ar, plottage_area, deal_area, jimok,
                land_use, share_dealing_type, dealing_gbn, data_type
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s,
                      %s, %s, %s, %s, %s, %s, %s, %s)
        """, (
            item.get('deal_year'),
            item.get('deal_month'),
            item.get('deal_day'),
            item.get('district'),
            item.get('umdNm'),
            deal_amount,  # ë³€í™˜ëœ ê±°ë˜ê¸ˆì•¡ì„ ì „ë‹¬
            item.get('house_type'),
            item.get('apt_name'),
            item.get('jibun'),
            item.get('floor'),
            item.get('exclu_use_ar'),
            item.get('plottage_area'),
            item.get('deal_area'),
            item.get('jimok'),
            item.get('land_use'),
            item.get('share_dealing_type'),
            item.get('dealing_gbn'),
            data_type
        ))

    conn.commit()



# ì„œìš¸íŠ¹ë³„ì‹œ ëª¨ë“  êµ¬ ë¦¬ìŠ¤íŠ¸
seoul_gu_list = [
    "ê°•ë‚¨êµ¬", "ê°•ë™êµ¬", "ê°•ë¶êµ¬", "ê°•ì„œêµ¬", "ê´€ì•…êµ¬", "ê´‘ì§„êµ¬", "êµ¬ë¡œêµ¬", "ê¸ˆì²œêµ¬", "ë…¸ì›êµ¬",
    "ë„ë´‰êµ¬", "ë™ëŒ€ë¬¸êµ¬", "ë™ì‘êµ¬", "ë§ˆí¬êµ¬", "ì„œëŒ€ë¬¸êµ¬", "ì„œì´ˆêµ¬", "ì„±ë™êµ¬", "ì„±ë¶êµ¬", "ì†¡íŒŒêµ¬",
    "ì–‘ì²œêµ¬", "ì˜ë“±í¬êµ¬", "ìš©ì‚°êµ¬", "ì€í‰êµ¬", "ì¢…ë¡œêµ¬", "ì¤‘êµ¬", "ì¤‘ë‘êµ¬"
]
for seoul in seoul_gu_list:
    redevelopment_info = get_redevelopment_info(seoul)

    for deal_day in recent_3_months:
        print(f"\nğŸ“¦ {deal_day} | {seoul} ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")

        filtered_single_deals = []
        filtered_apt_deals = []
        filtered_multi_generational_deals = []
        filtered_land_sale_deals = []
        unique_law_dong_codes = []
        unique_neighborhoods = []

        # unique ì •ë³´ ì¶”ì¶œ
        for item in redevelopment_info:
            neighborhood = item['neighborhood']
            if neighborhood not in unique_neighborhoods:
                unique_neighborhoods.append(neighborhood)

        for item in redevelopment_info:
            law_dong_code = item['law_dong_code']
            if law_dong_code and law_dong_code != '':
                code_prefix = int(law_dong_code[:5])
                if code_prefix not in unique_law_dong_codes:
                    unique_law_dong_codes.append(code_prefix)

        if not unique_law_dong_codes:
            print("âŒ ë²•ì •ë™ì½”ë“œ ì—†ìŒ - ìŠ¤í‚µ")
            continue

        # API ìš”ì²­ ë° í•„í„°ë§
        real_single_family_deals = get_real_single_family_home_deals(unique_law_dong_codes[0], deal_day, REAL_TRANSACTION_KEY)
        real_multi_generational_deals = get_villa_deals(unique_law_dong_codes[0], deal_day, REAL_TRANSACTION_KEY)
        real_land_sale_deals = get_land_sale_deals(unique_law_dong_codes[0], deal_day, REAL_TRANSACTION_KEY)

        filtered_single_deals = filter_real_deals(real_single_family_deals, unique_neighborhoods)
        filtered_multi_generational_deals = filter_real_deals(real_multi_generational_deals, unique_neighborhoods)
        filtered_land_sale_deals = filter_real_deals(real_land_sale_deals, unique_neighborhoods)

        # DB ì €ì¥ ë° ì¶œë ¥
        # ë‹¨ë… ë‹¤ê°€êµ¬ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥
        for item in filtered_single_deals:
            count += 1
            item["district"] = seoul
            print(item)
        insert_real_estate_data(cursor, conn, filtered_single_deals, "ë‹¨ë…")

        # ì—°ë¦½ ë‹¤ì„¸ëŒ€ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥
        for item in filtered_multi_generational_deals:
            count += 1
            item["district"] = seoul
            print(item)
        insert_real_estate_data(cursor, conn, filtered_multi_generational_deals, "ì—°ë¦½")

        # í† ì§€ ë§¤ë§¤ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥
        for item in filtered_land_sale_deals:
            count += 1
            item["district"] = seoul
            print(item)
        insert_real_estate_data(cursor, conn, filtered_land_sale_deals, "í† ì§€")

cursor.close()
conn.close()
print(f"ì¡°íšŒëœ ì„œìš¸ì‹œ ì¬ê°œë°œ ì´ ë°ì´í„° ê°¯ìˆ˜: {count}ê°œ" )
